{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_path = '/root/autodl-tmp/Word2Vec-Implementation-with-PyTorch/models/skipgram-5e.pth'\n",
    "device = 'cpu'\n",
    "model = torch.load(model_path, weights_only=False, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloader import get_dataloader_and_tokenizer\n",
    "\n",
    "dataloader, tokenizer = get_dataloader_and_tokenizer(1, 4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2127327043557479"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = 0\n",
    "length = tokenizer.get_vocab_size()\n",
    "for i in range(length):\n",
    "    i = torch.tensor(i).to(device)\n",
    "    a, b = model.V(i).unsqueeze(0), model.W(i).unsqueeze(0)\n",
    "    avg += F.cosine_similarity(a,b).item()\n",
    "avg / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结论一： V[a] !~ W[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityVW(token1, token2):\n",
    "    token1 = torch.tensor(tokenizer.token_to_idx(token1)).to(device)\n",
    "    token2 = torch.tensor(tokenizer.token_to_idx(token2)).to(device)\n",
    "    a, b = model.V(token1).unsqueeze(0), model.W(token2).unsqueeze(0)\n",
    "    return F.cosine_similarity(a,b).item()\n",
    "\n",
    "def similarityVV(token1, token2):\n",
    "    token1 = torch.tensor(tokenizer.token_to_idx(token1)).to(device)\n",
    "    token2 = torch.tensor(tokenizer.token_to_idx(token2)).to(device)\n",
    "    a, b = model.V(token1).unsqueeze(0), model.V(token2).unsqueeze(0)\n",
    "    return F.cosine_similarity(a,b).item()\n",
    "\n",
    "def similarityWW(token1, token2):\n",
    "    token1 = torch.tensor(tokenizer.token_to_idx(token1)).to(device)\n",
    "    token2 = torch.tensor(tokenizer.token_to_idx(token2)).to(device)\n",
    "    a, b = model.W(token1).unsqueeze(0), model.W(token2).unsqueeze(0)\n",
    "    return F.cosine_similarity(a,b).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_tokens(token, mode=0, topn=15): # mode = 0: VV else VW\n",
    "    sims = {}\n",
    "    token = tokenizer.token_to_idx(token)\n",
    "    similarity = similarityVV if mode==0 else similarityVW if mode == 1 else similarityWW\n",
    "    for i in range(tokenizer.get_vocab_size()):\n",
    "        if i == token:\n",
    "            continue\n",
    "        sims[tokenizer.idx_to_token(i)] = similarity(tokenizer.idx_to_token(token), tokenizer.idx_to_token(i))\n",
    "    topn_tokens = sorted(sims.items(), key=lambda x: x[1], reverse=True)[:topn]\n",
    "    return topn_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('emperor', 0.7604710459709167),\n",
       "  ('monarch', 0.7218049168586731),\n",
       "  ('reign', 0.7002407908439636),\n",
       "  ('lord', 0.6984412670135498),\n",
       "  ('son', 0.6885751485824585),\n",
       "  ('successor', 0.6871017813682556),\n",
       "  ('queen', 0.6797590255737305),\n",
       "  ('frederick', 0.6781752705574036),\n",
       "  ('brother', 0.6703252196311951),\n",
       "  ('iv', 0.660991907119751),\n",
       "  ('odaenathus', 0.6607653498649597),\n",
       "  ('pope', 0.6564509868621826),\n",
       "  ('archbishop', 0.6424189209938049),\n",
       "  ('bishop', 0.6360291242599487),\n",
       "  ('founder', 0.6351824998855591)],\n",
       " [(\"'s\", 0.6255903244018555),\n",
       "  ('of', 0.6003551483154297),\n",
       "  ('the', 0.5648436546325684),\n",
       "  ('to', 0.5593847632408142),\n",
       "  ('his', 0.5588068962097168),\n",
       "  ('<unk>', 0.5560933351516724),\n",
       "  (',', 0.55524080991745),\n",
       "  ('was', 0.5482189655303955),\n",
       "  ('and', 0.5375607013702393),\n",
       "  ('\"', 0.5242669582366943),\n",
       "  ('as', 0.5165198445320129),\n",
       "  ('.', 0.5160472989082336),\n",
       "  ('in', 0.5139936208724976),\n",
       "  ('who', 0.5129943490028381),\n",
       "  ('he', 0.5060199499130249)],\n",
       " [('henry', 0.5892033576965332),\n",
       "  ('edward', 0.5758170485496521),\n",
       "  ('son', 0.5471718311309814),\n",
       "  ('charles', 0.5206059813499451),\n",
       "  ('john', 0.4963080883026123),\n",
       "  ('william', 0.4878859519958496),\n",
       "  ('brother', 0.48773258924484253),\n",
       "  ('lord', 0.48654478788375854),\n",
       "  ('reign', 0.4805898368358612),\n",
       "  ('queen', 0.47211360931396484),\n",
       "  ('earl', 0.4622587561607361),\n",
       "  ('pope', 0.46087223291397095),\n",
       "  ('bishop', 0.4574088454246521),\n",
       "  ('daughter', 0.45088762044906616),\n",
       "  ('emperor', 0.4454230070114136)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_tokens('king'), most_similar_tokens('king', mode=1), most_similar_tokens('king', mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 300\n",
    "a = most_similar_tokens('king', mode=1, topn=n)\n",
    "b = most_similar_tokens('monarch', mode=1, topn=n)\n",
    "a = {i for i,j in a}\n",
    "b = {i for i,j in b}\n",
    "len(a&b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plane', 0.612949013710022),\n",
       " ('remainder', 0.5949611663818359),\n",
       " ('wearing', 0.5851904153823853),\n",
       " ('point', 0.5847347378730774),\n",
       " ('1929', 0.5814406871795654),\n",
       " ('excavations', 0.5722891688346863),\n",
       " ('start', 0.5668984651565552),\n",
       " ('battle', 0.5657597184181213),\n",
       " ('pitched', 0.5612479448318481),\n",
       " ('appearing', 0.54886794090271),\n",
       " ('chorus', 0.5463493466377258),\n",
       " ('magadheera', 0.544417142868042),\n",
       " ('job', 0.542961061000824),\n",
       " ('period', 0.5426279902458191),\n",
       " ('loss', 0.5369955897331238)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_tokens('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3902110457420349"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarityVV('england', 'english')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
